# assistant_vocal_pro.py
import tempfile

import streamlit as st
import datetime
import json
import os
import requests
import random
import time
import re
import wikipedia
import threading
import queue
import subprocess
import sys
from datetime import datetime as dt
from typing import Optional, Dict, List, Tuple, Any
import pandas as pd
import numpy as np
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import logging
import hashlib
import textwrap
from difflib import get_close_matches
import html

# ========== CONFIGURATION ET LOGGING ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('assistant.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ========== ENUMS ET DATACLASSES ==========



class CommandType(Enum):
    TIME = "time"
    DATE = "date"
    WEATHER = "weather"
    CALCULATE = "calculate"
    SEARCH = "search"
    JOKE = "joke"
    REMINDER = "reminder"
    NEWS = "news"
    SYSTEM = "system"
    GREETING = "greeting"
    QUESTION = "question"
    CONVERSATION = "conversation"
    PROFESSIONAL = "professional"
    UNKNOWN = "unknown"


@dataclass
class ConversationEntry:
    id: str
    timestamp: str
    user_input: str
    assistant_response: str
    command_type: CommandType
    confidence: float = 1.0
    metadata: Optional[Dict] = None

    def to_dict(self):
        return {
            **asdict(self),
            'command_type': self.command_type.value
        }

class VoiceEngine(Enum):
    PYTTSX3 = "pyttsx3"
    GTTS = "gtts"
    EDGE_TTS = "edge_tts"
    ELEVENLABS = "elevenlabs"
    OPENAI_TTS = "openai_tts"
    SYSTEM = "system"
    DISABLED = "disabled"

@dataclass
class UserPreferences:
    name: str = "Monsieur"
    title: str = "M."  # M., Mme, Dr, Prof.
    default_city: str = "Paris"
    language: str = "fr"
    voice_enabled: bool = True
    voice_engine: VoiceEngine = VoiceEngine.PYTTSX3
    voice_speed: int = 170
    voice_volume: float = 1.0
    auto_speak: bool = True
    theme: str = "dark"
    notifications: bool = True
    professional_mode: bool = True
    response_style: str = "professional"  # professional, friendly, technical
    formality_level: str = "high"  # high, medium, low

    def to_dict(self):
        return {
            **asdict(self),
            'voice_engine': self.voice_engine.value
        }


# ========== GESTIONNAIRE DE CONFIGURATION ==========
class ConfigManager:
    """Gestionnaire de configuration centralis√©"""

    def __init__(self):
        self.config_dir = Path.home() / ".assistant_vocal_pro"
        self.config_dir.mkdir(exist_ok=True)

        self.config_file = self.config_dir / "config.json"
        self.history_file = self.config_dir / "history.json"
        self.cache_file = self.config_dir / "cache.json"
        self.knowledge_base = self.config_dir / "knowledge.json"
        self.user_profile = self.config_dir / "profile.json"

    def load_config(self) -> Dict:
        """Charger la configuration"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {}

    def save_config(self, config: Dict):
        """Sauvegarder la configuration"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur sauvegarde config: {e}")

    def load_history(self) -> List[Dict]:
        """Charger l'historique"""
        if self.history_file.exists():
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return []

    def save_history(self, history: List[Dict]):
        """Sauvegarder l'historique"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history[-1000:], f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur sauvegarde historique: {e}")

    def load_knowledge_base(self) -> Dict:
        """Charger la base de connaissances"""
        if self.knowledge_base.exists():
            try:
                with open(self.knowledge_base, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {
            "faq": {},
            "user_interests": [],
            "conversation_patterns": {},
            "professional_responses": {}
        }

    def save_knowledge_base(self, knowledge: Dict):
        """Sauvegarder la base de connaissances"""
        try:
            with open(self.knowledge_base, 'w', encoding='utf-8') as f:
                json.dump(knowledge, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur sauvegarde connaissance: {e}")


# ========== GESTIONNAIRE VOCAL AVANC√â ==========
class VoiceManager:
    """Gestionnaire vocal sophistiqu√© avec fallbacks multiples"""

    def __init__(self):
        self.engine_type = VoiceEngine.DISABLED
        self.engine = None
        self.is_speaking = False
        self.speech_queue = queue.Queue()
        self.worker_thread = None
        self.voice_lock = threading.Lock()  # Verrou pour √©viter les conflits
        self._initialize_engines()
        self._start_worker_thread()  # ‚úÖ Nom corrig√©
        self.voice_styles = {
            "professional": {"rate": 160, "volume": 0.9, "pitch": 110},
            "friendly": {"rate": 170, "volume": 1.0, "pitch": 120},
            "technical": {"rate": 150, "volume": 0.8, "pitch": 100}
        }

        # Ajouter les nouvelles voix humaines
        self.human_voices = {
            "male_professional": {"rate": 165, "volume": 0.9, "pitch": 115},
            "female_elegant": {"rate": 155, "volume": 0.9, "pitch": 125},
            "male_calm": {"rate": 160, "volume": 0.85, "pitch": 110},
            "female_warm": {"rate": 150, "volume": 0.95, "pitch": 130},
            "male_authoritative": {"rate": 145, "volume": 0.9, "pitch": 105},
            "female_friendly": {"rate": 170, "volume": 0.9, "pitch": 135}
        }

        self.current_voice = "male_professional"
        self.available_voices = {}

    def _initialize_engines(self):
        """Initialiser tous les moteurs vocaux disponibles"""
        self.engines = {}
        self.available_voices = {}

        # Essayer pyttsx3
        try:
            import pyttsx3
            engine = pyttsx3.init()

            # Configuration par d√©faut
            engine.setProperty('rate', 160)
            engine.setProperty('volume', 0.9)

            # Chercher une voix fran√ßaise
            voices = engine.getProperty('voices')
            french_voices = []
            all_voices = []

            for voice in voices:
                voice_info = {
                    'id': voice.id,
                    'name': voice.name,
                    'languages': voice.languages if hasattr(voice, 'languages') else [],
                    'gender': 'male' if 'male' in voice.name.lower() else 'female'
                }
                all_voices.append(voice_info)

                if any(lang in str(voice.languages).lower() for lang in ['fr', 'french', 'fr-fr']):
                    french_voices.append(voice)

            # Stocker les voix
            self.available_voices['pyttsx3'] = {
                'all': all_voices,
                'french': french_voices
            }

            if french_voices:
                engine.setProperty('voice', french_voices[0].id)
                logger.info(f"‚úÖ Voix fran√ßaise trouv√©e: {french_voices[0].name}")
            else:
                logger.warning("Aucune voix fran√ßaise trouv√©e, utilisation de la voix par d√©faut")

            self.engines[VoiceEngine.PYTTSX3] = engine
            self.engine_type = VoiceEngine.PYTTSX3
            logger.info("‚úÖ Moteur pyttsx3 initialis√©")
        except Exception as e:
            logger.warning(f"‚ùå pyttsx3 non disponible: {e}")

        # Essayer gTTS
        try:
            from gtts import gTTS
            import pygame
            pygame.mixer.init()
            self.engines[VoiceEngine.GTTS] = {
                'gtts': gTTS,
                'pygame': pygame,
                'cache': {}
            }
            if self.engine_type == VoiceEngine.DISABLED:
                self.engine_type = VoiceEngine.GTTS
            logger.info("‚úÖ Moteur gTTS initialis√©")
        except Exception as e:
            logger.warning(f"‚ùå gTTS non disponible: {e}")

        # Essayer Edge TTS (Microsoft - voix naturelles)
        try:
            import edge_tts
            self.engines[VoiceEngine.EDGE_TTS] = {
                'module': edge_tts,
                'voices': [
                    "fr-FR-DeniseNeural",  # Femme √©l√©gante
                    "fr-FR-HenriNeural",  # Homme professionnel
                    "fr-FR-AlainNeural",  # Homme calme
                    "fr-FR-VivienneNeural",  # Femme chaleureuse
                    "fr-FR-ClaudeNeural",  # Homme autoritaire
                    "fr-FR-JosephineNeural"  # Femme amicale
                ]
            }
            logger.info("‚úÖ Edge TTS initialis√© (voix Microsoft)")
        except ImportError:
            logger.info("‚ÑπÔ∏è Edge TTS non install√©. Installez avec: pip install edge-tts")

        # Essayer ElevenLabs (optionnel)
        try:
            import elevenlabs
            self.engines[VoiceEngine.ELEVENLABS] = {
                'module': elevenlabs,
                'voices': [],
                'api_key': None
            }
            logger.info("‚úÖ ElevenLabs disponible")
        except ImportError:
            pass  # Optionnel

        # Essayer voix syst√®me
        try:
            if sys.platform == 'darwin':  # macOS
                self.engines[VoiceEngine.SYSTEM] = 'say'
            elif sys.platform == 'win32':  # Windows
                try:
                    import win32com.client
                    speaker = win32com.client.Dispatch("SAPI.SpVoice")
                    speaker.Rate = 0
                    speaker.Volume = 100
                    self.engines[VoiceEngine.SYSTEM] = speaker
                except ImportError:
                    self.engines[VoiceEngine.SYSTEM] = None
            else:  # Linux
                self.engines[VoiceEngine.SYSTEM] = 'espeak'

            if self.engine_type == VoiceEngine.DISABLED and VoiceEngine.SYSTEM in self.engines:
                self.engine_type = VoiceEngine.SYSTEM
                logger.info("‚úÖ Moteur syst√®me initialis√©")
        except Exception as e:
            logger.warning(f"‚ùå Voix syst√®me non disponible: {e}")

    def _start_worker_thread(self):  # ‚úÖ Nom corrig√©
        """D√©marrer le thread de traitement vocal"""

        def worker():
            while True:
                try:
                    item = self.speech_queue.get(timeout=1)
                    if item is None:  # Signal d'arr√™t
                        break

                    text, style = item
                    self._speak_sync(text, style)
                    self.speech_queue.task_done()
                except queue.Empty:
                    continue
                except Exception as e:
                    logger.error(f"Erreur worker vocal: {e}")

        self.worker_thread = threading.Thread(target=worker, daemon=True)
        self.worker_thread.start()
        logger.info("‚úÖ Worker vocal d√©marr√©")

    def _speak_sync(self, text: str, style: str = "professional"):
        """Parler du texte de mani√®re synchrone"""
        with self.voice_lock:
            self.is_speaking = True

            try:
                # Nettoyer et pr√©parer le texte
                clean_text = self._prepare_speech_text(text, style)

                if self.engine_type == VoiceEngine.PYTTSX3 and VoiceEngine.PYTTSX3 in self.engines:
                    self._speak_pyttsx3(clean_text, style)

                elif self.engine_type == VoiceEngine.GTTS and VoiceEngine.GTTS in self.engines:
                    self._speak_gtts(clean_text)

                elif self.engine_type == VoiceEngine.EDGE_TTS and VoiceEngine.EDGE_TTS in self.engines:
                    self._speak_edge_tts(clean_text, style)

                elif self.engine_type == VoiceEngine.SYSTEM and VoiceEngine.SYSTEM in self.engines:
                    self._speak_system(clean_text)

                else:
                    logger.warning("Aucun moteur vocal disponible")

            except Exception as e:
                logger.error(f"Erreur lors de la synth√®se vocale: {e}")

            finally:
                self.is_speaking = False

    def _speak_pyttsx3(self, text: str, style: str):
        """Utiliser pyttsx3 avec gestion des erreurs"""
        try:
            engine = self.engines[VoiceEngine.PYTTSX3]

            # Arr√™ter proprement si d√©j√† en cours
            try:
                engine.stop()
            except:
                pass

            # Appliquer le style
            if style in self.voice_styles:
                config = self.voice_styles[style]
                engine.setProperty('rate', config["rate"])
                engine.setProperty('volume', config["volume"])

            engine.say(text)
            engine.runAndWait()

        except RuntimeError as e:
            if "run loop" in str(e):
                # Recr√©er le moteur
                import pyttsx3
                new_engine = pyttsx3.init()
                self.engines[VoiceEngine.PYTTSX3] = new_engine
                new_engine.say(text)
                new_engine.runAndWait()
            else:
                raise

    def _speak_gtts(self, text: str):
        """Utiliser gTTS avec cache"""
        try:
            import tempfile
            from gtts import gTTS
            import pygame

            engine_data = self.engines[VoiceEngine.GTTS]
            cache = engine_data['cache']

            # Utiliser le cache
            text_hash = hashlib.md5(text.encode()).hexdigest()

            if text_hash in cache:
                audio_data = cache[text_hash]
            else:
                # G√©n√©rer l'audio
                tts = gTTS(text=text, lang='fr', slow=False)
                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as f:
                    temp_file = f.name
                    tts.save(temp_file)

                with open(temp_file, 'rb') as f:
                    audio_data = f.read()

                cache[text_hash] = audio_data
                os.unlink(temp_file)

            # Jouer l'audio
            pygame.mixer.init()
            temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            temp_audio.write(audio_data)
            temp_audio.close()

            pygame.mixer.music.load(temp_audio.name)
            pygame.mixer.music.play()

            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

            os.unlink(temp_audio.name)

        except Exception as e:
            logger.error(f"Erreur gTTS: {e}")

    def _speak_edge_tts(self, text: str, style: str = "professional"):
        """Utiliser Edge TTS (Microsoft) - voix naturelles"""
        try:
            import asyncio
            import edge_tts
            import tempfile

            # Mapping des styles aux voix Edge TTS
            voice_map = {
                "professional": "fr-FR-HenriNeural",
                "friendly": "fr-FR-JosephineNeural",
                "technical": "fr-FR-AlainNeural",
                "male_professional": "fr-FR-HenriNeural",
                "female_elegant": "fr-FR-DeniseNeural",
                "male_calm": "fr-FR-AlainNeural",
                "female_warm": "fr-FR-VivienneNeural",
                "male_authoritative": "fr-FR-ClaudeNeural",
                "female_friendly": "fr-FR-JosephineNeural"
            }

            voice = voice_map.get(style, "fr-FR-HenriNeural")

            # Cr√©er un event loop
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

            # Cr√©er le communicateur
            communicate = edge_tts.Communicate(text, voice)

            # Fichier temporaire
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
                tmp_path = tmp_file.name

            # G√©n√©rer l'audio
            async def generate():
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        with open(tmp_path, "ab") as audio_file:
                            audio_file.write(chunk["data"])

            loop.run_until_complete(generate())
            loop.close()

            # Jouer avec pygame
            import pygame
            pygame.mixer.init()
            pygame.mixer.music.load(tmp_path)
            pygame.mixer.music.play()

            while pygame.mixer.music.get_busy():
                time.sleep(0.1)

            # Nettoyer
            os.unlink(tmp_path)

        except Exception as e:
            logger.error(f"Erreur Edge TTS: {e}")

    def _speak_system(self, text: str):
        """Utiliser la voix syst√®me"""
        system_engine = self.engines[VoiceEngine.SYSTEM]

        if isinstance(system_engine, str):
            if sys.platform == 'darwin':  # macOS
                os.system(f'say "{text}" -v Thomas -r 160')
            elif sys.platform == 'linux':
                os.system(f'espeak -v french+m3 "{text}" -s 160 -p 50')
        else:
            # Windows COM
            system_engine.Speak(text)

    def _prepare_speech_text(self, text: str, style: str) -> str:
        """Pr√©parer le texte pour la synth√®se vocale"""
        # Supprimer le markdown et HTML
        clean = re.sub(r'[#*_\-\[\](){}`]', '', text)
        clean = re.sub(r'<[^>]+>', '', clean)

        # Remplacer les sauts de ligne
        clean = re.sub(r'\n+', '. ', clean)

        # Ajouter des pauses naturelles
        if style == "professional":
            clean = re.sub(r'[.!?]', '...', clean)
        elif style == "technical":
            clean = re.sub(r',', '...', clean)

        # Limiter la longueur mais intelligemment
        sentences = re.split(r'[.!?]', clean)
        if len(sentences) > 3:
            clean = '. '.join(sentences[:3]) + '...'
        else:
            clean = clean[:600]

        return clean

    def speak(self, text: str, style: str = "professional", async_mode: bool = True):
        """Parler du texte avec un style sp√©cifique"""
        if self.engine_type == VoiceEngine.DISABLED:
            return False

        if async_mode:
            self.speech_queue.put((text, style))
            return True
        else:
            self._speak_sync(text, style)
            return True

    def set_engine(self, engine_type: VoiceEngine):
        """Changer le moteur vocal"""
        if engine_type in self.engines:
            self.engine_type = engine_type
            return True
        return False

    def set_voice_style(self, style: str):
        """Changer le style de voix"""
        if style in self.human_voices or style in self.voice_styles:
            self.current_voice = style
            return True
        return False

    def get_available_engines(self) -> List[VoiceEngine]:
        """Obtenir la liste des moteurs disponibles"""
        return list(self.engines.keys())

    def stop(self):
        """Arr√™ter le gestionnaire vocal"""
        self.speech_queue.put(None)
        if self.worker_thread:
            self.worker_thread.join(timeout=1)

# ========== BASE DE CONNAISSANCES INTELLIGENTE ==========
class KnowledgeBase:
    """Base de connaissances pour r√©ponses professionnelles"""

    def __init__(self):
        self.config_manager = ConfigManager()
        self.knowledge = self.config_manager.load_knowledge_base()
        self._initialize_default_knowledge()

    def _initialize_default_knowledge(self):
        """Initialiser les connaissances par d√©faut"""
        if "professional_responses" not in self.knowledge:
            self.knowledge["professional_responses"] = {
                "greetings": [
                    "Je vous salue, {title} {name}. En quoi puis-je vous assister aujourd'hui ?",
                    "Bonjour {title} {name}, je suis √† votre enti√®re disposition.",
                    "Mes respects, {title} {name}. Que puis-je faire pour vous ?"
                ],
                "farewells": [
                    "Au revoir {title} {name}. Ce fut un plaisir de vous assister.",
                    "Je vous souhaite une excellente journ√©e, {title} {name}.",
                    "√Ä tr√®s bient√¥t, {title} {name}. N'h√©sitez pas si vous avez besoin d'assistance."
                ],
                "acknowledgments": [
                    "Je vous remercie de votre question, {title} {name}.",
                    "Tr√®s bonne question, {title} {name}. Permettez-moi de vous r√©pondre.",
                    "J'appr√©cie votre demande, {title} {name}. Voici ma r√©ponse."
                ],
                "uncertain": [
                    "Permettez-moi de vous proposer une perspective sur ce sujet, {title} {name}.",
                    "Si je comprends bien votre demande, {title} {name}, voici ce que je peux vous dire.",
                    "D'apr√®s mes analyses, {title} {name}, voici les informations pertinentes."
                ]
            }

        if "common_topics" not in self.knowledge:
            self.knowledge["common_topics"] = {
                "business": [
                    "strat√©gie d'entreprise", "management", "leadership", "productivit√©",
                    "innovation", "croissance", "finance", "marketing", "ventes"
                ],
                "technology": [
                    "intelligence artificielle", "machine learning", "d√©veloppement",
                    "cloud computing", "cybers√©curit√©", "data science", "blockchain"
                ],
                "general": [
                    "sant√©", "√©ducation", "voyage", "culture", "sport", "politique",
                    "√©conomie", "environnement", "science"
                ]
            }

        self.config_manager.save_knowledge_base(self.knowledge)

    def get_professional_response(self, category: str, name: str = "Monsieur", title: str = "M.") -> str:
        """Obtenir une r√©ponse professionnelle"""
        responses = self.knowledge.get("professional_responses", {}).get(category, [])
        if responses:
            template = random.choice(responses)
            return template.format(name=name, title=title)
        return ""

    def learn_from_interaction(self, question: str, response: str, category: str):
        """Apprendre de nouvelles interactions"""
        if "learned_patterns" not in self.knowledge:
            self.knowledge["learned_patterns"] = {}

        key = hashlib.md5(question.lower().encode()).hexdigest()
        self.knowledge["learned_patterns"][key] = {
            "question": question,
            "response": response,
            "category": category,
            "timestamp": dt.now().isoformat(),
            "usage_count": 1
        }

        self.config_manager.save_knowledge_base(self.knowledge)

    def find_similar_question(self, question: str) -> Optional[Dict]:
        """Trouver une question similaire dans la base"""
        if "learned_patterns" not in self.knowledge:
            return None

        questions = list(self.knowledge["learned_patterns"].values())
        if not questions:
            return None

        # Recherche simple par similarit√© de mots-cl√©s
        question_lower = question.lower()
        for q_data in questions:
            stored_q = q_data["question"].lower()
            # V√©rifier les mots communs
            common_words = set(question_lower.split()) & set(stored_q.split())
            if len(common_words) >= 2:  # Au moins 2 mots communs
                q_data["usage_count"] += 1
                return q_data

        return None


# ========== ASSISTANT INTELLIGENT PROFESSIONNEL ==========
class ProfessionalAssistant:
    """Assistant IA professionnel avec compr√©hension contextuelle avanc√©e"""

    def __init__(self):
        self.config_manager = ConfigManager()
        self.voice_manager = VoiceManager()
        self.speech_recognizer = SpeechRecognizer()
        self.knowledge_base = KnowledgeBase()
        self.user_prefs = self._load_preferences()

        # Initialiser Wikipedia
        try:
            wikipedia.set_lang("fr")
            wikipedia.set_rate_limiting(True)
        except:
            pass

        # Cache pour les recherches
        self.cache = {}
        self.conversation_history = self.config_manager.load_history()

        # Context conversationnel
        self.context = {
            "last_topic": None,
            "user_mood": "neutral",
            "conversation_depth": 0,
            "user_interests": set()
        }

        # API Keys
        self.weather_api_key = os.getenv("WEATHER_API_KEY", "")
        self.news_api_key = os.getenv("NEWS_API_KEY", "")

        logger.info("ü§ñ Assistant professionnel initialis√©")

    def _load_preferences(self) -> UserPreferences:
        """Charger les pr√©f√©rences utilisateur"""
        config = self.config_manager.load_config()

        if config:
            try:
                return UserPreferences(
                    name=config.get('name', 'Monsieur'),
                    title=config.get('title', 'M.'),
                    default_city=config.get('default_city', 'Paris'),
                    language=config.get('language', 'fr'),
                    voice_enabled=config.get('voice_enabled', True),
                    voice_engine=VoiceEngine(config.get('voice_engine', 'pyttsx3')),
                    voice_speed=config.get('voice_speed', 170),
                    voice_volume=config.get('voice_volume', 1.0),
                    auto_speak=config.get('auto_speak', True),
                    theme=config.get('theme', 'dark'),
                    notifications=config.get('notifications', True),
                    professional_mode=config.get('professional_mode', True),
                    response_style=config.get('response_style', 'professional'),
                    formality_level=config.get('formality_level', 'high')
                )
            except:
                pass

        return UserPreferences()

    def save_preferences(self):
        """Sauvegarder les pr√©f√©rences"""
        config = self.user_prefs.to_dict()
        self.config_manager.save_config(config)

    # ========== ANALYSE INTELLIGENTE ==========

    def _analyze_intent_with_context(self, text: str) -> Tuple[CommandType, Dict, float]:
        """Analyser l'intention avec contexte conversationnel"""
        text_lower = text.lower()
        metadata = {"confidence": 1.0}

        # V√©rifier d'abord dans les patterns appris
        similar = self.knowledge_base.find_similar_question(text)
        if similar:
            metadata["learned_response"] = similar["response"]
            metadata["category"] = similar["category"]
            metadata["confidence"] = 0.9
            return CommandType.CONVERSATION, metadata, 0.9

        # D√©tection de type de question
        question_types = {
            "who": r'qui est|qui sont|qui a|qui √©tait',
            "what": r'qu\'est-ce que|qu\'est-ce qu\'|c\'est quoi|d√©finition de',
            "when": r'quand|date|√† quelle date|quelle date',
            "where": r'o√π|o√π se trouve|lieu de|localisation',
            "why": r'pourquoi|raison de|cause de',
            "how": r'comment|de quelle mani√®re|de quelle fa√ßon'
        }

        for q_type, pattern in question_types.items():
            if re.search(pattern, text_lower):
                metadata["question_type"] = q_type
                break

        # Analyse s√©mantique avanc√©e
        if self._is_greeting(text_lower):
            return CommandType.GREETING, metadata, 0.95

        elif self._is_time_question(text_lower):
            return CommandType.TIME, metadata, 0.9

        elif self._is_date_question(text_lower):
            return CommandType.DATE, metadata, 0.9

        elif self._is_weather_question(text_lower):
            return CommandType.WEATHER, metadata, 0.85

        elif self._is_calculation(text_lower):
            return CommandType.CALCULATE, metadata, 0.95

        elif self._is_search_query(text_lower):
            return CommandType.SEARCH, metadata, 0.8

        elif self._is_joke_request(text_lower):
            return CommandType.JOKE, metadata, 0.9

        elif self._is_news_request(text_lower):
            return CommandType.NEWS, metadata, 0.85

        else:
            # Pour toute autre question, retourner QUESTION avec r√©ponse professionnelle
            return CommandType.QUESTION, metadata, 0.7

    def _is_greeting(self, text: str) -> bool:
        greetings = ['bonjour', 'salut', 'hello', 'hi', 'coucou', 'bonsoir']
        return any(greet in text for greet in greetings)

    def _is_time_question(self, text: str) -> bool:
        patterns = [r'heure', r'quelle heure', r'l\'heure', r'horloge', r'qu\'il est']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_date_question(self, text: str) -> bool:
        patterns = [r'date', r'aujourd\'hui', r'quel jour', r'nous sommes']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_weather_question(self, text: str) -> bool:
        patterns = [r'm√©t√©o', r'temps', r'temp√©rature', r'pluie', r'soleil', r'nuage']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_calculation(self, text: str) -> bool:
        patterns = [r'\d+[\s]*[+\-*/%^]\s*\d+', r'calcule', r'calcul', r'combien font', r'√©gal √†']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_search_query(self, text: str) -> bool:
        patterns = [r'recherche', r'cherche', r'trouve', r'c\'est quoi', r'qui est', r'd√©finition']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_joke_request(self, text: str) -> bool:
        patterns = [r'blague', r'humour', r'rire', r'amusant', r'dr√¥le']
        return any(re.search(pattern, text) for pattern in patterns)

    def _is_news_request(self, text: str) -> bool:
        patterns = [r'actualit√©s', r'news', r'infos', r'nouvelles', r'journal']
        return any(re.search(pattern, text) for pattern in patterns)

    # ========== R√âPONSES PROFESSIONNELLES ==========

    def get_professional_response(self, user_input: str) -> Tuple[str, CommandType]:
        """Obtenir une r√©ponse professionnelle pour toute question"""
        # Analyser l'intention
        command_type, metadata, confidence = self._analyze_intent_with_context(user_input)

        # Mettre √† jour le contexte
        self._update_conversation_context(user_input, command_type)

        # G√©n√©rer la r√©ponse selon le type
        if command_type == CommandType.GREETING:
            response = self._get_professional_greeting()

        elif command_type == CommandType.TIME:
            response = self._get_time_response_professional()

        elif command_type == CommandType.DATE:
            response = self._get_date_response_professional()

        elif command_type == CommandType.WEATHER:
            response = self._get_weather_response_professional(user_input)

        elif command_type == CommandType.CALCULATE:
            response = self._get_calculation_response_professional(user_input)

        elif command_type == CommandType.SEARCH:
            response = self._get_search_response_professional(user_input)

        elif command_type == CommandType.JOKE:
            response = self._get_joke_response_professional()

        elif command_type == CommandType.NEWS:
            response = self._get_news_response_professional()

        elif command_type == CommandType.QUESTION:
            response = self._get_general_response_professional(user_input)

        elif command_type == CommandType.CONVERSATION:
            response = metadata.get("learned_response",
                                    self._get_general_response_professional(user_input))
        else:
            response = self._get_fallback_professional(user_input)

        # Ajouter l'entr√©e de conversation
        entry_id = hashlib.md5(f"{dt.now().isoformat()}{user_input}".encode()).hexdigest()[:8]
        entry = ConversationEntry(
            id=entry_id,
            timestamp=dt.now().isoformat(),
            user_input=user_input,
            assistant_response=response,
            command_type=command_type,
            confidence=confidence,
            metadata=metadata
        )

        # Ajouter √† l'historique
        self.conversation_history.append(entry.to_dict())
        self.config_manager.save_history(self.conversation_history)

        # Apprendre de l'interaction
        if confidence > 0.8:
            self.knowledge_base.learn_from_interaction(
                user_input, response, command_type.value
            )

        return response, command_type

    def _update_conversation_context(self, user_input: str, command_type: CommandType):
        """Mettre √† jour le contexte conversationnel"""
        self.context["last_topic"] = command_type
        self.context["conversation_depth"] += 1

        # D√©tecter l'humeur
        positive_words = ['merci', 'super', 'g√©nial', 'parfait', 'excellent']
        negative_words = ['pourquoi pas', 'pas bon', 'mauvais', 'insuffisant']

        if any(word in user_input.lower() for word in positive_words):
            self.context["user_mood"] = "positive"
        elif any(word in user_input.lower() for word in negative_words):
            self.context["user_mood"] = "negative"

        # Extraire les int√©r√™ts potentiels
        topics = ['technologie', 'science', 'affaires', 'finance', 'sant√©', 'voyage']
        for topic in topics:
            if topic in user_input.lower():
                self.context["user_interests"].add(topic)

    def _get_professional_greeting(self) -> str:
        """Salutation professionnelle"""
        now = dt.now()
        hour = now.hour

        if 5 <= hour < 12:
            period = "matin"
            greeting_style = "√©nergique"
        elif 12 <= hour < 14:
            period = "midi"
            greeting_style = "courtois"
        elif 14 <= hour < 18:
            period = "apr√®s-midi"
            greeting_style = "professionnel"
        elif 18 <= hour < 22:
            period = "soir"
            greeting_style = "chaleureux"
        else:
            period = "nuit"
            greeting_style = "respectueux"

        greetings = {
            "√©nergique": [
                f"Bonjour {self.user_prefs.title} {self.user_prefs.name} ! Une excellente journ√©e commence. Comment puis-je vous servir ?",
                f"Je vous salue {self.user_prefs.title} {self.user_prefs.name}. Une nouvelle journ√©e productive s'annonce !"
            ],
            "courtois": [
                f"Bonjour {self.user_prefs.title} {self.user_prefs.name}. J'esp√®re que votre journ√©e se d√©roule bien. Je suis √† votre service.",
                f"Je vous souhaite un bon d√©jeuner {self.user_prefs.title} {self.user_prefs.name}. En quoi puis-je vous assister ?"
            ],
            "professionnel": [
                f"Bon apr√®s-midi {self.user_prefs.title} {self.user_prefs.name}. Je suis disponible pour r√©pondre √† toutes vos requ√™tes professionnelles.",
                f"Je vous salue {self.user_prefs.title} {self.user_prefs.name}. Pr√™t √† optimiser votre productivit√© cet apr√®s-midi."
            ],
            "chaleureux": [
                f"Bonsoir {self.user_prefs.title} {self.user_prefs.name}. J'esp√®re que votre journ√©e a √©t√© productive. Comment puis-je vous aider ?",
                f"Bonne soir√©e {self.user_prefs.title} {self.user_prefs.name}. Je reste √† votre disposition pour toute assistance."
            ],
            "respectueux": [
                f"Bonne nuit {self.user_prefs.title} {self.user_prefs.name}. M√™me √† cette heure, je suis disponible pour vous.",
                f"Je vous salue {self.user_prefs.title} {self.user_prefs.name}. N'h√©sitez pas √† solliciter mes services, quelle que soit l'heure."
            ]
        }

        return random.choice(greetings[greeting_style])

    def _get_time_response_professional(self) -> str:
        """Heure avec √©l√©gance professionnelle"""
        now = dt.now()

        hour = now.hour
        minute = now.minute
        second = now.second

        # Formulation √©l√©gante
        if minute == 0:
            time_str = f"{hour} heures pr√©cises"
        elif minute < 10:
            time_str = f"{hour} heures et {minute} minute{'' if minute == 1 else 's'}"
        elif minute == 15:
            time_str = f"{hour} heures et quart"
        elif minute == 30:
            time_str = f"{hour} heures et demie"
        elif minute == 45:
            next_hour = hour + 1 if hour < 23 else 0
            time_str = f"{next_hour} heures moins le quart"
        else:
            time_str = f"{hour} heures {minute}"

        # Contexte professionnel
        if 9 <= hour < 12:
            context = "P√©riode id√©ale pour les r√©unions strat√©giques."
        elif 12 <= hour < 14:
            context = "Moment parfait pour une pause d√©jeuner productive."
        elif 14 <= hour < 17:
            context = "Heure de travail intense et de concentration."
        elif 17 <= hour < 19:
            context = "Fin de journ√©e professionnelle approchant."
        else:
            context = "Temps de r√©flexion et de planification."

        return (
            f"üïê **Heure actuelle :** {time_str} et {second} seconde{'' if second == 1 else 's'}\n\n"
            f"*Contexte professionnel :* {context}\n\n"
            f"**{self.user_prefs.title} {self.user_prefs.name}**, je vous recommande de v√©rifier votre agenda pour les prochains rendez-vous."
        )

    def _get_date_response_professional(self) -> str:
        """Date avec informations professionnelles"""
        now = dt.now()

        months = [
            'janvier', 'f√©vrier', 'mars', 'avril', 'mai', 'juin',
            'juillet', 'ao√ªt', 'septembre', 'octobre', 'novembre', 'd√©cembre'
        ]

        days = [
            'Lundi', 'Mardi', 'Mercredi', 'Jeudi',
            'Vendredi', 'Samedi', 'Dimanche'
        ]

        day_name = days[now.weekday()]
        month_name = months[now.month - 1]

        # Informations professionnelles
        day_of_year = now.timetuple().tm_yday
        quarter = (now.month - 1) // 3 + 1

        # Calcul des jours travaill√©s restants (simplifi√©)
        if now.weekday() < 5:  # Lundi √† vendredi
            work_days_left = 5 - now.weekday()
        else:
            work_days_left = 0

        return (
            f"üìÖ **Date actuelle :** {day_name} {now.day} {month_name} {now.year}\n\n"
            f"**Informations professionnelles :**\n"
            f"‚Ä¢ Trimestre en cours : Q{quarter}\n"
            f"‚Ä¢ Jour {day_of_year}/365 de l'ann√©e\n"
            f"‚Ä¢ Semaine {now.isocalendar()[1]} de l'ann√©e\n"
            f"‚Ä¢ Jours ouvr√©s restants cette semaine : {work_days_left}\n\n"
            f"**{self.user_prefs.title} {self.user_prefs.name}**, c'est le moment id√©al pour planifier vos objectifs trimestriels."
        )

    def _get_weather_response_professional(self, query: str) -> str:
        """M√©t√©o avec conseils professionnels"""
        # Extraire la ville
        cities = ['paris', 'londres', 'tunis', 'new york', 'tokyo', 'berlin']
        city = self.user_prefs.default_city

        for c in cities:
            if c in query.lower():
                city = c.capitalize()
                break

        try:
            if self.weather_api_key:
                url = "http://api.openweathermap.org/data/2.5/weather"
                params = {
                    'q': city,
                    'appid': self.weather_api_key,
                    'units': 'metric',
                    'lang': 'fr'
                }

                response = requests.get(url, params=params, timeout=5)

                if response.status_code == 200:
                    data = response.json()

                    temp = data['main']['temp']
                    feels_like = data['main']['feels_like']
                    humidity = data['main']['humidity']
                    description = data['weather'][0]['description'].capitalize()
                    wind_speed = data['wind']['speed']

                    # Conseils professionnels selon la m√©t√©o
                    if temp < 5:
                        advice = "‚ùÑÔ∏è **Conseil professionnel :** Pr√©voyez des r√©unions en pr√©sentiel pour cr√©er de la chaleur humaine."
                        clothing = "Tenue formelle avec manteau chaud recommand√©e."
                    elif temp < 15:
                        advice = "üß• **Conseil professionnel :** Conditions id√©ales pour des r√©unions productives en pr√©sentiel."
                        clothing = "Costume ou tenue professionnelle avec veste l√©g√®re."
                    elif temp < 25:
                        advice = "üòä **Conseil professionnel :** Parfait pour des √©v√©nements en ext√©rieur ou des brainstorming cr√©atifs."
                        clothing = "Tenue professionnelle l√©g√®re, possibilit√© de retirer la veste."
                    else:
                        advice = "üåû **Conseil professionnel :** Privil√©giez les r√©unions virtuelles pour le confort ou climatisez vos bureaux."
                        clothing = "Tenue professionnelle l√©g√®re en tissus respirants."

                    return (
                        f"üå§Ô∏è **Rapport m√©t√©orologique professionnel - {city}**\n\n"
                        f"**Conditions actuelles :** {description}\n"
                        f"**üå°Ô∏è Temp√©rature :** {temp:.1f}¬∞C (ressentie {feels_like:.1f}¬∞C)\n"
                        f"**üíß Humidit√© :** {humidity}%\n"
                        f"**üí® Vitesse du vent :** {wind_speed} m/s\n\n"
                        f"**Tenue professionnelle recommand√©e :**\n{clothing}\n\n"
                        f"{advice}\n\n"
                        f"*Ces informations peuvent influencer la planification de vos d√©placements professionnels.*"
                    )

            # Fallback simul√©
            simulated_data = {
                'temp': random.randint(10, 25),
                'description': random.choice(['Ensoleill√©', 'Partiellement nuageux', 'Nuageux', 'L√©g√®re pluie']),
                'humidity': random.randint(40, 80)
            }

            return (
                f"üå§Ô∏è **Pr√©visions m√©t√©o pour {city}**\n\n"
                f"**üå°Ô∏è Temp√©rature estim√©e :** {simulated_data['temp']}¬∞C\n"
                f"**üìä Conditions :** {simulated_data['description']}\n"
                f"**üíß Humidit√© relative :** {simulated_data['humidity']}%\n\n"
                f"**{self.user_prefs.title} {self.user_prefs.name}**, pour des donn√©es pr√©cises, "
                f"configurez votre cl√© API OpenWeatherMap dans les param√®tres."
            )

        except Exception as e:
            logger.error(f"Erreur m√©t√©o: {e}")
            return (
                f"üå§Ô∏è **Service m√©t√©o temporairement indisponible**\n\n"
                f"Je vous recommande de consulter une source m√©t√©o fiable pour {city}.\n"
                f"Pour une assistance professionnelle optimale, veuillez configurer votre cl√© API."
            )

    def _get_calculation_response_professional(self, expression: str) -> str:
        """Calculatrice professionnelle"""
        try:
            # Nettoyer l'expression
            expr = expression.lower()

            # Remplacer les termes textuels
            replacements = {
                'plus': '+', 'moins': '-', 'fois': '*', 'multipli√© par': '*',
                'divis√© par': '/', 'sur': '/', 'pourcent': '*0.01', '%': '*0.01*',
                'au carr√©': '**2', 'carr√©': '**2', 'au cube': '**3', 'cube': '**3',
                'racine carr√©e de': 'math.sqrt(', 'racine de': 'math.sqrt(',
                'puissance': '**', 'exposant': '**', '√† la puissance': '**',
                'pi': 'math.pi', 'œÄ': 'math.pi', 'e': 'math.e'
            }

            for word, symbol in replacements.items():
                expr = expr.replace(word, symbol)

            # Ajouter des parenth√®ses pour sqrt
            if 'math.sqrt(' in expr:
                expr = expr.replace('math.sqrt', 'math.sqrt')

            # Validation de s√©curit√©
            import math

            # Liste des fonctions math√©matiques autoris√©es
            allowed_names = {
                'math.sqrt': math.sqrt,
                'math.pi': math.pi,
                'math.e': math.e,
                'math.sin': math.sin,
                'math.cos': math.cos,
                'math.tan': math.tan,
                'math.log': math.log,
                'math.log10': math.log10,
                'math.exp': math.exp
            }

            # √âvaluer en s√©curit√©
            code = compile(expr, '<string>', 'eval')
            for name in code.co_names:
                if name not in allowed_names:
                    raise NameError(f"Utilisation de {name} non autoris√©e")

            result = eval(code, {"__builtins__": {}}, allowed_names)

            # Formatage professionnel
            if isinstance(result, (int, float)):
                if isinstance(result, float):
                    if abs(result) > 1e6 or abs(result) < 1e-6:
                        result_str = f"{result:.4e}"
                    elif result.is_integer():
                        result_str = f"{int(result):,}".replace(',', ' ')
                    else:
                        result_str = f"{result:,.4f}".replace(',', ' ').rstrip('0').rstrip('.')
                else:
                    result_str = f"{result:,}".replace(',', ' ')

                # Analyse du r√©sultat
                if result > 1000000:
                    magnitude = "r√©sultat significatif"
                elif result < 0.0001 and result > 0:
                    magnitude = "valeur pr√©cise"
                else:
                    magnitude = "calcul standard"

                return (
                    f"üßÆ **Analyse math√©matique professionnelle**\n\n"
                    f"**Expression :** {expression}\n"
                    f"**R√©sultat :** {result_str}\n"
                    f"**Type :** {magnitude}\n\n"
                    f"**{self.user_prefs.title} {self.user_prefs.name}**, ce r√©sultat peut √™tre utilis√© pour :\n"
                    f"‚Ä¢ Analyses financi√®res\n‚Ä¢ Projections statistiques\n‚Ä¢ Calculs techniques\n‚Ä¢ Planification strat√©gique"
                )
            else:
                return f"**R√©sultat :** {result}"

        except Exception as e:
            # R√©ponse professionnelle m√™me en cas d'erreur
            return (
                f"üßÆ **Analyse de l'expression math√©matique**\n\n"
                f"**Expression fournie :** {expression}\n\n"
                f"**Note technique :** L'expression n√©cessite une reformulation pour √™tre √©valu√©e.\n"
                f"**Suggestion :** Veuillez formuler votre calcul en utilisant des op√©rateurs math√©matiques standard (+, -, *, /, ^).\n\n"
                f"**Exemple professionnel :** 'Calcule le retour sur investissement de 15000‚Ç¨ avec un taux de 5% sur 3 ans'"
            )

    def _get_search_response_professional(self, query: str) -> str:
        """Recherche professionnelle"""
        # Nettoyer la requ√™te
        clean_query = re.sub(
            r'(recherche|cherche|trouve|informations sur|d√©tails sur|connais-tu|sais-tu)',
            '',
            query,
            flags=re.IGNORECASE
        ).strip()

        try:
            # Essayer Wikipedia
            try:
                search_results = wikipedia.search(clean_query, results=3)

                if search_results:
                    # Prendre le premier r√©sultat
                    page = wikipedia.page(search_results[0], auto_suggest=False)

                    # Nettoyer le r√©sum√©
                    summary = page.summary
                    summary = re.sub(r'\([^)]*\)', '', summary)  # Supprimer les parenth√®ses
                    summary = re.sub(r'\[[^\]]*\]', '', summary)  # Supprimer les crochets

                    # Couper intelligemment
                    sentences = summary.split('. ')
                    if len(sentences) > 4:
                        summary = '. '.join(sentences[:4]) + '...'

                    return (
                        f"üîç **Recherche professionnelle : {search_results[0]}**\n\n"
                        f"{summary}\n\n"
                        f"**Source :** Wikipedia\n"
                        f"**Fiabilit√© :** Source encyclop√©dique\n\n"
                        f"**{self.user_prefs.title} {self.user_prefs.name}**, ces informations peuvent servir de base √† :\n"
                        f"‚Ä¢ Une analyse pr√©liminaire\n‚Ä¢ Une recherche documentaire\n‚Ä¢ Une pr√©paration de pr√©sentation"
                    )
            except:
                pass

            # Fallback professionnel
            return (
                f"üîç **Recherche : {clean_query}**\n\n"
                f"**Analyse s√©mantique :** Sujet identifi√© comme pertinent pour recherche approfondie.\n\n"
                f"**Recommandations professionnelles :**\n"
                f"1. Consulter des bases de donn√©es acad√©miques (Google Scholar, JSTOR)\n"
                f"2. Examiner la litt√©rature professionnelle du domaine\n"
                f"3. Contacter des experts du secteur\n\n"
                f"**{self.user_prefs.title} {self.user_prefs.name}**, pour une recherche exhaustive, "
                f"je vous recommande d'utiliser des moteurs de recherche sp√©cialis√©s."
            )

        except Exception as e:
            logger.error(f"Erreur recherche: {e}")
            return (
                f"üîç **Service de recherche temporairement limit√©**\n\n"
                f"**Sujet :** {clean_query}\n\n"
                f"**Conseil professionnel :** Pour des informations d√©taill√©es sur '{clean_query}', "
                f"je vous recommande de consulter :\n"
                f"‚Ä¢ Les publications sp√©cialis√©es\n‚Ä¢ Les rapports d'industrie\n‚Ä¢ Les √©tudes de march√©\n\n"
                f"Je reste disponible pour toute autre assistance."
            )

    def _get_joke_response_professional(self) -> str:
        """Humour professionnel"""
        categories = {
            'management': [
                "Pourquoi le manager a-t-il emmen√© une √©chelle aux r√©unions ? Pour atteindre des conclusions √©lev√©es.",
                "Combien de managers faut-il pour changer une ampoule ? Aucun, ils d√©l√®guent la t√¢che tout en supervisant le processus.",
                "Quelle est la diff√©rence entre un mauvais manager et un bon manager ? Le bon manager transforme les probl√®mes en opportunit√©s, le mauvais transforme les opportunit√©s en probl√®mes."
            ],
            'technologie': [
                "Pourquoi les donn√©es ont-elles refus√© de traverser la route ? Parce qu'elles n'√©taient pas autoris√©es √† quitter leur base.",
                "Comment appelle-t-on un informaticien qui n'a pas de caf√© ? Un programme qui ne compile pas.",
                "Pourquoi les d√©veloppeurs pr√©f√®rent-ils le noir ? Parce que la lumi√®re attire les bugs."
            ],
            'business': [
                "Pourquoi l'√©conomiste a-t-il pris un parapluie ? Parce qu'on pr√©voyait des liquidit√©s.",
                "Quelle est la diff√©rence entre un optimiste et un pessimiste en affaires ? L'optimiste voit le verre √† moiti√© plein, le pessimiste voit le verre √† moiti√© vide, et le chef d'entreprise voit le verre deux fois trop grand.",
                "Pourquoi le comptable a-t-il travers√© la route ? Pour v√©rifier que la transaction √©tait correctement enregistr√©e des deux c√¥t√©s."
            ]
        }

        category = random.choice(list(categories.keys()))
        joke = random.choice(categories[category])

        return (
            f"üòä **Moment de d√©tente professionnelle**\n\n"
            f"**Cat√©gorie :** {category.capitalize()}\n\n"
            f"\"{joke}\"\n\n"
            f"*Un peu d'humour peut am√©liorer la productivit√© de 15% selon certaines √©tudes.*"
        )

    def _get_news_response_professional(self) -> str:
        """Actualit√©s professionnelles"""
        sectors = [
            "Technologie et Innovation",
            "March√©s Financiers",
            "D√©veloppement Durable",
            "Intelligence Artificielle",
            "Transformation Digitale"
        ]

        sector = random.choice(sectors)

        headlines = {
            "Technologie et Innovation": [
                "Nouvelles avanc√©es en informatique quantique promettent de r√©volutionner le calcul.",
                "La 5G continue son d√©ploiement mondial avec des implications majeures pour l'IoT.",
                "Les edge computing gagnent en importance pour le traitement des donn√©es en temps r√©el."
            ],
            "March√©s Financiers": [
                "Les march√©s s'adaptent aux nouvelles politiques mon√©taires globales.",
                "La finance durable attire de plus en plus d'investissements institutionnels.",
                "Les cryptomonnaies √©voluent vers une r√©gulation plus structur√©e."
            ],
            "D√©veloppement Durable": [
                "Les entreprises acc√©l√®rent leur transition vers des mod√®les circulaires.",
                "Les √©nergies renouvelables atteignent des records d'adoption mondiale.",
                "L'√©conomie verte cr√©e de nouveaux emplois et opportunit√©s commerciales."
            ]
        }

        news = random.choice(headlines.get(sector, ["D√©veloppements significatifs dans le secteur"]))

        return (
            f"üì∞ **Bulletin d'actualit√©s professionnelles**\n\n"
            f"**Secteur :** {sector}\n\n"
            f"**Titre :** {news}\n\n"
            f"**Implications professionnelles :**\n"
            f"‚Ä¢ Opportunit√©s de d√©veloppement\n‚Ä¢ √âvolution du march√©\n‚Ä¢ Consid√©rations strat√©giques\n\n"
            f"**{self.user_prefs.title} {self.user_prefs.name}**, pour rester comp√©titif, "
            f"je recommande une veille informationnelle r√©guli√®re sur ce secteur."
        )

    def _get_general_response_professional(self, query: str) -> str:
        """R√©ponse professionnelle g√©n√©rale pour toute question"""
        # Analyser le type de question
        if '?' in query:
            question_type = "interrogative"
        elif any(word in query.lower() for word in ['explique', 'd√©cris', 'parle-moi']):
            question_type = "explicative"
        else:
            question_type = "declarative"

        # R√©ponses professionnelles adapt√©es
        responses = {
            "interrogative": [
                f"**{self.user_prefs.title} {self.user_prefs.name}**, votre question '{query}' soul√®ve des points int√©ressants. "
                f"D'apr√®s mon analyse, je peux vous indiquer que ce sujet fait l'objet de discussions dans les milieux professionnels. "
                f"Pour une r√©ponse exhaustive, je recommande une √©tude approfondie des sources sp√©cialis√©es.",

                f"**Analyse professionnelle de votre question :**\n\n"
                f"**Sujet :** {query}\n"
                f"**Complexit√© :** Moyenne √† √©lev√©e\n"
                f"**Pertinence :** Actuelle\n\n"
                f"**Recommandation :** Consulter des experts du domaine ou des publications acad√©miques r√©centes "
                f"pour obtenir une perspective compl√®te."
            ],
            "explicative": [
                f"**Explication professionnelle demand√©e :**\n\n"
                f"Le sujet '{query}' peut √™tre abord√© sous plusieurs angles professionnels :\n"
                f"1. **Angle th√©orique** : Concepts fondamentaux et principes directeurs\n"
                f"2. **Angle pratique** : Applications concr√®tes et √©tudes de cas\n"
                f"3. **Angle strat√©gique** : Implications commerciales et opportunit√©s\n\n"
                f"**{self.user_prefs.title} {self.user_prefs.name}**, pour une explication d√©taill√©e, "
                f"je sugg√®re de pr√©ciser l'angle qui vous int√©resse.",

                f"**Cadre d'explication professionnel :**\n\n"
                f"Le th√®me '{query}' rel√®ve g√©n√©ralement des domaines suivants :\n"
                f"‚Ä¢ Recherche et d√©veloppement\n‚Ä¢ Analyse de march√©\n‚Ä¢ Gestion de projet\n‚Ä¢ Innovation technologique\n\n"
                f"Chaque domaine apporte un √©clairage sp√©cifique et des m√©thodologies distinctes."
            ],
            "declarative": [
                f"**Observation professionnelle :**\n\n"
                f"Votre d√©claration '{query}' refl√®te une perspective int√©ressante sur le sujet. "
                f"Dans un contexte professionnel, cela pourrait √™tre li√© √† :\n"
                f"‚Ä¢ Des tendances sectorielles\n‚Ä¢ Des √©volutions du march√©\n‚Ä¢ Des innovations m√©thodologiques\n\n"
                f"**{self.user_prefs.title} {self.user_prefs.name}**, souhaitez-vous approfondir un aspect particulier ?",

                f"**Analyse contextuelle :**\n\n"
                f"Le contenu de votre message '{query}' s'inscrit dans plusieurs cadres professionnels possibles. "
                f"Pour une assistance optimale, pourriez-vous pr√©ciser le contexte d'application ?\n\n"
                f"**Exemples de contextes :**\n- D√©veloppement d'entreprise\n- Recherche acad√©mique\n- Consultation strat√©gique"
            ]
        }

        return random.choice(responses[question_type])

    def _get_fallback_professional(self, query: str) -> str:
        """R√©ponse professionnelle de secours"""
        return (
            f"**{self.user_prefs.title} {self.user_prefs.name}**, je prends note de votre demande concernant '{query}'.\n\n"
            f"**Approche professionnelle recommand√©e :**\n"
            f"1. **D√©finition du besoin** : Clarifier les objectifs sp√©cifiques\n"
            f"2. **Recherche d'information** : Consulter des sources sp√©cialis√©es\n"
            f"3. **Analyse contextuelle** : √âvaluer les implications professionnelles\n"
            f"4. **Synth√®se et recommandations** : Formuler des propositions actionnables\n\n"
            f"Je suis disponible pour vous accompagner dans cette d√©marche professionnelle."
        )

    # ========== INTERFACE PUBLIQUE ==========

    def process_command(self, command: str) -> str:
        """Traiter une commande utilisateur de mani√®re professionnelle"""
        if not command or not command.strip():
            return f"**{self.user_prefs.title} {self.user_prefs.name}**, pourriez-vous reformuler votre demande ? Je suis attentif √† votre requ√™te."

        # Obtenir la r√©ponse professionnelle
        response, command_type = self.get_professional_response(command)

        # Parler la r√©ponse si activ√©
        if self.user_prefs.auto_speak and self.user_prefs.voice_enabled:
            style = self.user_prefs.response_style
            self.voice_manager.speak(response, style=style)

        return response

    def listen_and_process(self) -> Optional[str]:
        """√âcouter et traiter une commande vocale professionnelle"""
        if not self.speech_recognizer.recognizer:
            return (
                f"**{self.user_prefs.title} {self.user_prefs.name}**, le service vocal n√©cessite une configuration suppl√©mentaire.\n\n"
                f"**Solution professionnelle :**\n"
                f"1. V√©rifier la connexion du microphone\n"
                f"2. Installer les d√©pendances audio n√©cessaires\n"
                f"3. Autoriser l'acc√®s microphone dans les param√®tres syst√®me\n\n"
                f"En attendant, vous pouvez utiliser la saisie textuelle pour une assistance imm√©diate."
            )

        # Feedback visuel
        with st.spinner("üé§ **√âcoute professionnelle en cours... Veuillez parler clairement.**"):
            time.sleep(0.5)

            # √âcouter avec param√®tres optimis√©s
            command = self.speech_recognizer.listen(timeout=7, phrase_time_limit=10)

        if command:
            return self.process_command(command)
        elif command == "":
            return f"**{self.user_prefs.title} {self.user_prefs.name}**, je n'ai pas saisi votre message clairement. Pourriez-vous reformuler ou utiliser la saisie textuelle ?"
        else:
            return f"**{self.user_prefs.title} {self.user_prefs.name}**, je n'ai d√©tect√© aucune entr√©e vocale. V√©rifiez votre microphone ou utilisez l'interface texte pour une assistance optimale."

    def get_conversation_history(self, limit: int = 20) -> List[Dict]:
        """Obtenir l'historique des conversations"""
        return self.conversation_history[-limit:] if self.conversation_history else []

    def clear_history(self):
        """Effacer l'historique"""
        self.conversation_history = []
        self.config_manager.save_history([])

    def get_stats(self) -> Dict:
        """Obtenir des statistiques d'utilisation professionnelles"""
        if not self.conversation_history:
            return {}

        # Compter les types de commandes
        type_counts = {}
        confidence_total = 0

        for entry in self.conversation_history:
            cmd_type = entry.get('command_type', 'unknown')
            type_counts[cmd_type] = type_counts.get(cmd_type, 0) + 1
            confidence_total += entry.get('confidence', 1.0)

        avg_confidence = confidence_total / len(self.conversation_history) if self.conversation_history else 0

        # Identifier les sujets fr√©quents
        topics = {}
        for entry in self.conversation_history[-50:]:  # Derniers 50 messages
            if 'metadata' in entry and entry['metadata']:
                category = entry['metadata'].get('category')
                if category:
                    topics[category] = topics.get(category, 0) + 1

        return {
            'total_commands': len(self.conversation_history),
            'command_types': type_counts,
            'average_confidence': round(avg_confidence, 2),
            'frequent_topics': dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5]),
            'first_interaction': self.conversation_history[0]['timestamp'] if self.conversation_history else None,
            'last_interaction': self.conversation_history[-1]['timestamp'] if self.conversation_history else None,
            'user_name': self.user_prefs.name,
            'professional_level': self.user_prefs.formality_level
        }


# ========== RECONNAISSANCE VOCALE (version existante avec am√©liorations) ==========
class SpeechRecognizer:
    """Reconnaissance vocale avec gestion d'erreurs avanc√©e"""

    def __init__(self):
        self.recognizer = None
        self.microphone = None
        self._initialize()

    # Dans la classe SpeechRecognizer, ajoutez un bloc try-except plus robuste
    def _initialize(self):
        """Initialiser la reconnaissance vocale"""
        try:
            import speech_recognition as sr
            self.recognizer = sr.Recognizer()

            # V√©rification de la disponibilit√© du microphone
            try:
                self.microphone = sr.Microphone()
                # Test rapide
                with self.microphone as source:
                    self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                logger.info("‚úÖ Microphone d√©tect√© et configur√©")
            except OSError as e:
                logger.warning(f"‚ùå Aucun microphone disponible: {e}")
                self.microphone = None

            return True
        except ImportError:
            logger.warning("‚ö†Ô∏è Module speech_recognition non install√©")
            logger.info("‚ÑπÔ∏è Installez avec: pip install SpeechRecognition pyaudio")
            return False

    def get_engine_display_names(self):
        """Obtenir les noms d'affichage des moteurs disponibles"""
        display_names = {
            VoiceEngine.PYTTSX3: "üíª Pyttsx3 (Local - Rapide)",
            VoiceEngine.GTTS: "üåê Google TTS (Qualit√© moyenne)",
            VoiceEngine.EDGE_TTS: "üéµ Edge TTS (Microsoft - Naturel)",
            VoiceEngine.ELEVENLABS: "üåü ElevenLabs (Premium - Ultra r√©aliste)",
            VoiceEngine.OPENAI_TTS: "ü§ñ OpenAI TTS (IA avanc√©e)",
            VoiceEngine.SYSTEM: "‚öôÔ∏è Voix syst√®me (Native)",
            VoiceEngine.DISABLED: "üîá D√©sactiv√©"
        }

        available = {}
        for engine in self.get_available_engines():
            available[display_names.get(engine, engine.value)] = engine

        return available

    def listen(self, timeout: int = 5, phrase_time_limit: int = 8) -> Optional[str]:
        """√âcouter et transcrire la parole"""
        if not self.recognizer or not self.microphone:
            return None

        try:
            with self.microphone as source:
                # Ajustement dynamique du bruit avec plusieurs √©chantillons
                self.recognizer.adjust_for_ambient_noise(source, duration=1)

                # Message audio
                logger.info("üé§ √âcoute en cours...")

                # √âcoute avec param√®tres optimis√©s
                audio = self.recognizer.listen(
                    source,
                    timeout=timeout,
                    phrase_time_limit=phrase_time_limit
                )

                # Reconnaissance avec Google (meilleure qualit√©)
                text = self.recognizer.recognize_google(
                    audio,
                    language='fr-FR',
                    show_all=False
                )

                logger.info(f"‚úÖ Texte reconnu: {text}")
                return text.lower()

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur reconnaissance: {e}")
            return None


# ========== INTERFACE STREAMLIT PROFESSIONNELLE ==========
class ProfessionalAssistantUI:
    """Interface utilisateur professionnelle pour l'assistant"""

    def __init__(self):
        self.assistant = ProfessionalAssistant()
        self.setup_page()
        self.initialize_session()

    def setup_page(self):
        """Configurer la page Streamlit professionnellement"""
        st.set_page_config(
            page_title="ü§ñ Assistant Vocal Professionnel Elite",
            page_icon="ü§ñ",
            layout="wide",
            initial_sidebar_state="expanded",
            menu_items={
                'Get Help': 'https://github.com/votre-repo',
                'Report a bug': 'https://github.com/votre-repo/issues',
                'About': """
                # ü§ñ Assistant Vocal Professionnel Elite

                ## Version 4.0 - √âdition Professionnelle

                **Fonctionnalit√©s principales :**
                - R√©ponses professionnelles √† 100% des questions
                - Synth√®se vocale avanc√©e
                - Interface √©l√©gante et intuitive
                - Analyse contextuelle intelligente
                - Base de connaissances auto-apprenante

                **Technologies :** Python, Streamlit, IA, NLP
                """
            }
        )

        # CSS professionnel
        self._inject_professional_css()

    def _inject_professional_css(self):
        """Injecter le CSS professionnel"""
        st.markdown("""
        <style>
            /* Th√®me professionnel */
            .stApp {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            }

            /* Header √©l√©gant */
            .professional-header {
                background: rgba(255, 255, 255, 0.15);
                backdrop-filter: blur(20px);
                border-radius: 25px;
                padding: 2.5rem;
                margin-bottom: 2rem;
                border: 1px solid rgba(255, 255, 255, 0.25);
                box-shadow: 0 15px 35px rgba(0, 0, 0, 0.2);
                position: relative;
                overflow: hidden;
            }

            .professional-header::before {
                content: '';
                position: absolute;
                top: 0;
                left: 0;
                right: 0;
                height: 3px;
                background: linear-gradient(90deg, #667eea, #764ba2);
            }

            /* Cartes professionnelles */
            .professional-card {
                background: rgba(255, 255, 255, 0.98);
                border-radius: 20px;
                padding: 2rem;
                margin: 1.5rem 0;
                box-shadow: 0 8px 30px rgba(0, 0, 0, 0.12);
                transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
                border-left: 6px solid #667eea;
                border-right: 1px solid rgba(102, 126, 234, 0.1);
                border-top: 1px solid rgba(102, 126, 234, 0.1);
                border-bottom: 1px solid rgba(102, 126, 234, 0.1);
            }

            .professional-card:hover {
                transform: translateY(-8px);
                box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
                border-left-color: #764ba2;
            }

            /* Messages de conversation */
            .user-message-pro {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 1.25rem 1.75rem;
                border-radius: 25px 25px 10px 25px;
                margin: 1.25rem 0 1.25rem auto;
                max-width: 85%;
                box-shadow: 0 6px 20px rgba(102, 126, 234, 0.25);
                position: relative;
                animation: slideInRightPro 0.4s cubic-bezier(0.4, 0, 0.2, 1);
                border: 1px solid rgba(255, 255, 255, 0.1);
            }

            .user-message-pro::before {
                content: 'üë§';
                position: absolute;
                left: -45px;
                top: 50%;
                transform: translateY(-50%);
                background: white;
                width: 35px;
                height: 35px;
                border-radius: 50%;
                display: flex;
                align-items: center;
                justify-content: center;
                box-shadow: 0 4px 12px rgba(0,0,0,0.15);
                font-size: 16px;
            }

            .assistant-message-pro {
                background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
                color: white;
                padding: 1.25rem 1.75rem;
                border-radius: 25px 25px 25px 10px;
                margin: 1.25rem auto 1.25rem 0;
                max-width: 85%;
                box-shadow: 0 6px 20px rgba(79, 172, 254, 0.25);
                position: relative;
                animation: slideInLeftPro 0.4s cubic-bezier(0.4, 0, 0.2, 1);
                border: 1px solid rgba(255, 255, 255, 0.1);
            }

            .assistant-message-pro::before {
                content: 'ü§ñ';
                position: absolute;
                right: -45px;
                top: 50%;
                transform: translateY(-50%);
                background: white;
                width: 35px;
                height: 35px;
                border-radius: 50%;
                display: flex;
                align-items: center;
                justify-content: center;
                box-shadow: 0 4px 12px rgba(0,0,0,0.15);
                font-size: 16px;
            }

            @keyframes slideInRightPro {
                from { 
                    transform: translateX(40px) scale(0.95);
                    opacity: 0; 
                }
                to { 
                    transform: translateX(0) scale(1);
                    opacity: 1; 
                }
            }

            @keyframes slideInLeftPro {
                from { 
                    transform: translateX(-40px) scale(0.95);
                    opacity: 0; 
                }
                to { 
                    transform: translateX(0) scale(1);
                    opacity: 1; 
                }
            }

            /* Boutons professionnels */
            .stButton > button {
                border-radius: 12px;
                padding: 0.85rem 2rem;
                font-weight: 600;
                transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
                border: none;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                font-size: 1rem;
                letter-spacing: 0.5px;
                position: relative;
                overflow: hidden;
            }

            .stButton > button::before {
                content: '';
                position: absolute;
                top: 0;
                left: -100%;
                width: 100%;
                height: 100%;
                background: linear-gradient(90deg, transparent, rgba(255,255,255,0.2), transparent);
                transition: left 0.7s;
            }

            .stButton > button:hover {
                transform: translateY(-3px);
                box-shadow: 0 10px 25px rgba(0, 0, 0, 0.25);
            }

            .stButton > button:hover::before {
                left: 100%;
            }

            .stButton > button:active {
                transform: translateY(-1px);
            }

            /* Indicateur vocal professionnel */
            .voice-indicator-pro {
                display: flex;
                align-items: center;
                gap: 15px;
                padding: 15px 20px;
                background: linear-gradient(135deg, rgba(102, 126, 234, 0.15), rgba(118, 75, 162, 0.15));
                border-radius: 15px;
                margin: 15px 0;
                border: 1px solid rgba(255, 255, 255, 0.1);
                backdrop-filter: blur(10px);
            }

            .voice-dot-pro {
                width: 12px;
                height: 12px;
                background: linear-gradient(135deg, #10B981, #059669);
                border-radius: 50%;
                animation: voicePulsePro 1.5s infinite ease-in-out;
            }

            @keyframes voicePulsePro {
                0%, 100% { 
                    opacity: 0.6; 
                    transform: scale(1); 
                }
                50% { 
                    opacity: 1; 
                    transform: scale(1.3); 
                }
            }

            /* Statistiques professionnelles */
            .stat-card-pro {
                text-align: center;
                padding: 1.5rem;
                background: white;
                border-radius: 15px;
                box-shadow: 0 6px 20px rgba(0,0,0,0.08);
                transition: transform 0.3s;
                border: 1px solid rgba(102, 126, 234, 0.1);
            }

            .stat-card-pro:hover {
                transform: translateY(-5px);
            }

            .stat-value-pro {
                font-size: 2.5rem;
                font-weight: 800;
                background: linear-gradient(135deg, #667eea, #764ba2);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                margin: 0.5rem 0;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            }

            .stat-label-pro {
                font-size: 0.9rem;
                color: #666;
                text-transform: uppercase;
                letter-spacing: 1px;
                font-weight: 600;
            }

            /* Input professionnel */
            .stTextArea textarea {
                border-radius: 15px !important;
                border: 2px solid rgba(102, 126, 234, 0.2) !important;
                padding: 1rem !important;
                font-size: 1rem !important;
                transition: border-color 0.3s !important;
            }

            .stTextArea textarea:focus {
                border-color: #667eea !important;
                box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1) !important;
            }

            /* Sidebar professionnelle */
            .css-1d391kg {
                background: linear-gradient(135deg, rgba(102, 126, 234, 0.05), rgba(118, 75, 162, 0.05));
                backdrop-filter: blur(10px);
            }

            /* Loading spinner */
            .stSpinner > div {
                border-color: #667eea transparent transparent transparent !important;
            }

            /* Alertes */
            .stAlert {
                border-radius: 15px !important;
                border-left: 6px solid !important;
            }

            /* Divider */
            .css-1v0mbdj {
                border-color: rgba(255, 255, 255, 0.1) !important;
            }
        </style>
        """, unsafe_allow_html=True)

    def initialize_session(self):
        """Initialiser l'√©tat de la session"""
        if 'conversation' not in st.session_state:
            st.session_state.conversation = []

        if 'last_response' not in st.session_state:
            st.session_state.last_response = None

        if 'listening' not in st.session_state:
            st.session_state.listening = False

        if 'auto_scroll' not in st.session_state:
            st.session_state.auto_scroll = True

    def render_header(self):
        """Afficher l'en-t√™te professionnel"""
        col1, col2, col3 = st.columns([2, 1, 1])

        with col1:
            st.markdown(f"""
            <div class="professional-header">
                <h1 style="margin: 0; color: white; font-size: 2.8rem; font-weight: 800;">
                    ü§ñ Assistant Vocal Professionnel Elite
                </h1>
                <p style="color: rgba(255, 255, 255, 0.95); margin: 15px 0 0 0; font-size: 1.2rem;">
                    Votre partenaire IA pour des r√©ponses professionnelles √† 100% de vos questions
                </p>
                <div style="display: flex; gap: 20px; margin-top: 20px;">
                    <div style="background: rgba(255,255,255,0.15); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">
                        üé§ Reconnaissance vocale avanc√©e
                    </div>
                    <div style="background: rgba(255,255,255,0.15); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">
                        üí¨ R√©ponses 100% professionnelles
                    </div>
                    <div style="background: rgba(255,255,255,0.15); padding: 8px 16px; border-radius: 20px; font-size: 0.9rem;">
                        üß† IA contextuelle intelligente
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            # Statut vocal
            voice_status = "‚úÖ Activ√©e" if self.assistant.user_prefs.voice_enabled else "üîá D√©sactiv√©e"
            st.markdown(f"""
            <div class="stat-card-pro" style="margin-top: 20px;">
                <div style="font-size: 1rem; color: #666;">√âtat Vocal</div>
                <div class="stat-value-pro">{'üé§' if self.assistant.user_prefs.voice_enabled else 'üîá'}</div>
                <div class="stat-label-pro">{voice_status}</div>
            </div>
            """, unsafe_allow_html=True)

        with col3:
            # Nombre de commandes
            stats = self.assistant.get_stats()
            total = stats.get('total_commands', 0)
            st.markdown(f"""
            <div class="stat-card-pro" style="margin-top: 20px;">
                <div style="font-size: 1rem; color: #666;">Interactions</div>
                <div class="stat-value-pro">{total}</div>
                <div class="stat-label-pro">Total</div>
            </div>
            """, unsafe_allow_html=True)

    def render_sidebar(self):
        """Afficher la barre lat√©rale professionnelle"""
        with st.sidebar:
            st.markdown("### ‚öôÔ∏è **Configuration Professionnelle**")

            # Profil professionnel
            with st.expander("üë§ **Profil Professionnel**", expanded=True):
                col_title, col_name = st.columns(2)
                with col_title:
                    title = st.selectbox(
                        "Titre",
                        ["M.", "Mme", "Dr", "Prof.", "Mlle"],
                        index=0,
                        help="Titre de civilit√© pour les communications formelles"
                    )
                    self.assistant.user_prefs.title = title

                with col_name:
                    name = st.text_input(
                        "Nom / Pr√©nom",
                        value=self.assistant.user_prefs.name,
                        placeholder="Votre nom professionnel",
                        help="Utilis√© pour les salutations personnalis√©es"
                    )
                    self.assistant.user_prefs.name = name

            # Param√®tres vocaux professionnels
            # Dans ProfessionalAssistantUI.render_sidebar() :

            with st.expander("üîä **Param√®tres Vocaux Avanc√©s**", expanded=True):
                voice_enabled = st.checkbox(
                    "Activer la synth√®se vocale",
                    value=self.assistant.user_prefs.voice_enabled,
                    help="L'assistant vocalise ses r√©ponses professionnelles"
                )
                self.assistant.user_prefs.voice_enabled = voice_enabled

                if voice_enabled:
                    # Style de voix humaine
                    voice_styles = list(self.assistant.voice_manager.human_voices.keys())
                    voice_style = st.selectbox(
                        "Style de voix",
                        voice_styles,
                        index=0,
                        format_func=lambda x: {
                            "male_professional": "üé© Homme Professionnel",
                            "female_elegant": "üë© Femme √âl√©gante",
                            "male_calm": "üòå Homme Calme",
                            "female_warm": "ü§ó Femme Chaleureuse",
                            "male_authoritative": "üëî Homme Autoritaire",
                            "female_friendly": "üëã Femme Amicale"
                        }.get(x, x),
                        help="Choisissez une voix naturelle et humaine"
                    )

                    # Appliquer le style
                    self.assistant.voice_manager.set_voice_style(voice_style)

                    # Moteurs vocaux avanc√©s
                    engines = self.assistant.voice_manager.get_available_engines()
                    engine_options = []

                    for engine in engines:
                        if engine == VoiceEngine.EDGE_TTS:
                            engine_options.append(("üéµ Edge TTS (Microsoft)", engine))
                        elif engine == VoiceEngine.ELEVENLABS:
                            engine_options.append(("üåü ElevenLabs (Premium)", engine))
                        elif engine == VoiceEngine.OPENAI_TTS:
                            engine_options.append(("ü§ñ OpenAI TTS", engine))
                        elif engine == VoiceEngine.PYTTSX3:
                            engine_options.append(("üíª Pyttsx3 (Local)", engine))
                        elif engine == VoiceEngine.GTTS:
                            engine_options.append(("üåê Google TTS", engine))
                        else:
                            engine_options.append((engine.value, engine))

                    if engine_options:
                        selected_display = st.selectbox(
                            "Moteur vocal",
                            options=[opt[0] for opt in engine_options],
                            index=0,
                            help="S√©lectionnez le moteur de synth√®se vocale"
                        )

                        # Trouver l'engine correspondant
                        selected_engine = None
                        for display, engine in engine_options:
                            if display == selected_display:
                                selected_engine = engine
                                break

                        if selected_engine:
                            self.assistant.user_prefs.voice_engine = selected_engine
                            self.assistant.voice_manager.set_engine(selected_engine)

                    # Test vocal avec diff√©rentes phrases
                    st.markdown("---")
                    st.markdown("#### üéß **Test des Voix**")

                    test_phrases = [
                        "Bonjour, je suis votre assistant professionnel.",
                        "La qualit√© de la communication est essentielle en affaires.",
                        "Cette voix vous semble-t-elle naturelle et agr√©able ?",
                        "Je suis l√† pour vous assister dans vos projets."
                    ]

                    selected_phrase = st.selectbox(
                        "Phrase de test",
                        test_phrases,
                        index=0
                    )

                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("üé§ Tester cette voix", use_container_width=True):
                            self.assistant.voice_manager.speak(
                                selected_phrase,
                                style=voice_style,
                                async_mode=False
                            )
                            st.success("‚úÖ Test vocal effectu√©")

                    with col2:
                        if st.button("üé≠ Tester toutes les voix", use_container_width=True):
                            with st.spinner("Test des diff√©rentes voix..."):
                                for style in voice_styles[:3]:  # Tester les 3 premi√®res
                                    self.assistant.voice_manager.set_voice_style(style)
                                    self.assistant.voice_manager.speak(
                                        f"Voix {style}: {selected_phrase}",
                                        style=style,
                                        async_mode=False
                                    )
                                    time.sleep(0.5)
                            st.success("‚úÖ Comparaison vocale termin√©e")
            # Pr√©f√©rences professionnelles
            with st.expander("üåç **Pr√©f√©rences Professionnelles**", expanded=False):
                city = st.selectbox(
                    "Ville de r√©f√©rence",
                    ['Paris', 'Londres', 'Tunis', 'New York', 'Tokyo', 'Berlin', 'Dubai', 'Singapore'],
                    index=0,
                    help="Ville utilis√©e pour les informations g√©olocalis√©es"
                )
                self.assistant.user_prefs.default_city = city

                formality = st.select_slider(
                    "Niveau de formalit√©",
                    options=["√âlev√©", "Moyen", "Bas"],
                    value="√âlev√©",
                    help="Niveau de formalit√© dans les communications"
                )
                self.assistant.user_prefs.formality_level = formality.lower()

            # Sauvegarde professionnelle
            st.markdown("---")
            if st.button("üíæ **Sauvegarder Configuration**", use_container_width=True, type="primary"):
                self.assistant.save_preferences()
                st.success("‚úÖ Configuration professionnelle sauvegard√©e")

            # Commandes rapides professionnelles
            st.markdown("### ‚ö° **Commandes Rapides**")

            quick_commands = [
                ("üïê", "Heure Actuelle", "quelle heure est-il actuellement"),
                ("üìÖ", "Date du Jour", "donne-moi la date d'aujourd'hui"),
                ("üå§Ô∏è", "Rapport M√©t√©o", f"m√©t√©o professionnelle pour {self.assistant.user_prefs.default_city}"),
                ("üîç", "Recherche Avanc√©e", "recherche sur l'intelligence artificielle"),
                ("üßÆ", "Calcul Expert", "calcule le retour sur investissement de 10000‚Ç¨ √† 5% sur 5 ans"),
                ("üìä", "Analyse", "analyse la situation √©conomique actuelle"),
                ("üíº", "Conseil", "donne-moi un conseil professionnel"),
                ("üìà", "Tendances", "quelles sont les tendances technologiques actuelles")
            ]

            for icon, label, cmd in quick_commands:
                if st.button(f"{icon} **{label}**",
                             key=f"sidebar_pro_{label}",
                             use_container_width=True):
                    with st.spinner(f"Traitement de la commande {label}..."):
                        response = self.assistant.process_command(cmd)
                        st.session_state.last_response = response
                        st.rerun()

    def render_main_content(self):
        """Afficher le contenu principal professionnel"""
        # Section conversation √©l√©gante
        st.markdown("### üí¨ **Conversation Professionnelle**")

        # Conteneur de conversation avec scroll
        conversation_container = st.container(height=450)

        with conversation_container:
            # Afficher l'historique r√©cent
            for entry in self.assistant.get_conversation_history(10):
                # Message utilisateur
                timestamp = entry['timestamp'][11:16] if 'timestamp' in entry else "N/A"

                st.markdown(f"""
                <div class="user-message-pro">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                        <strong style="font-size: 0.9rem;">{self.assistant.user_prefs.title} {self.assistant.user_prefs.name}</strong>
                        <small style="opacity: 0.8;">{timestamp}</small>
                    </div>
                    <div style="font-size: 1rem; line-height: 1.5;">{entry['user_input']}</div>
                </div>
                """, unsafe_allow_html=True)

                # Message assistant
                st.markdown(f"""
                <div class="assistant-message-pro">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                        <strong style="font-size: 0.9rem;">Assistant Professionnel Elite</strong>
                        <small style="opacity: 0.8;">{timestamp}</small>
                    </div>
                    <div style="font-size: 1rem; line-height: 1.5;">{entry['assistant_response']}</div>
                </div>
                """, unsafe_allow_html=True)

            # Afficher la derni√®re r√©ponse
            if st.session_state.last_response:
                current_time = dt.now().strftime('%H:%M')

                st.markdown(f"""
                <div class="assistant-message-pro">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px;">
                        <strong style="font-size: 0.9rem;">Assistant Professionnel Elite</strong>
                        <small style="opacity: 0.8;">{current_time}</small>
                    </div>
                    <div style="font-size: 1rem; line-height: 1.5;">{st.session_state.last_response}</div>
                </div>
                """, unsafe_allow_html=True)

                # Indicateur vocal
                if self.assistant.voice_manager.is_speaking:
                    st.markdown("""
                    <div class="voice-indicator-pro">
                        <div class="voice-dot-pro"></div>
                        <div class="voice-dot-pro" style="animation-delay: 0.2s"></div>
                        <div class="voice-dot-pro" style="animation-delay: 0.4s"></div>
                        <span style="color: #059669; font-weight: 700; font-size: 1rem;">
                            üîä Synth√®se vocale en cours...
                        </span>
                    </div>
                    """, unsafe_allow_html=True)

        # Contr√¥les de conversation professionnels
        col_controls1, col_controls2, col_controls3 = st.columns(3)

        with col_controls1:
            if st.button("üóëÔ∏è **Effacer Conversation**", use_container_width=True, type="secondary"):
                self.assistant.clear_history()
                st.session_state.last_response = None
                st.session_state.conversation = []
                st.rerun()

        with col_controls2:
            if st.button("üìä **Exporter Donn√©es**", use_container_width=True, type="secondary"):
                history = self.assistant.get_conversation_history()
                if history:
                    df = pd.DataFrame(history)
                    csv = df.to_csv(index=False, encoding='utf-8-sig')

                    st.download_button(
                        label="üì• **T√©l√©charger CSV**",
                        data=csv,
                        file_name=f"conversation_professionnelle_{dt.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )

        with col_controls3:
            if st.button("üîÑ **Actualiser Vue**", use_container_width=True, type="secondary"):
                st.rerun()

        # Section droite : Commandes et statistiques
        col_right1, col_right2 = st.columns([1, 1])

        with col_right1:
            # Contr√¥le vocal professionnel
            st.markdown("### üé§ **Commande Vocale**")

            if self.assistant.speech_recognizer.recognizer:
                if st.button("üé§ **PARLER √Ä L'ASSISTANT**",
                             type="primary",
                             use_container_width=True,
                             key="listen_pro_button"):

                    st.session_state.listening = True
                    with st.spinner("**Initialisation du microphone professionnel...**"):
                        time.sleep(0.3)

                    response = self.assistant.listen_and_process()
                    if response:
                        st.session_state.last_response = response
                        st.rerun()
            else:
                st.warning("‚ö†Ô∏è **Microphone non d√©tect√©**")
                st.info("""
                **Solution professionnelle :**
                1. Connectez un microphone
                2. Installez `speechrecognition` et `pyaudio`
                3. Autorisez l'acc√®s microphone

                *Utilisez la saisie texte en attendant.*
                """)

            st.markdown("---")

            # Statistiques avanc√©es
            st.markdown("### üìà **Analytiques Professionnelles**")

            stats = self.assistant.get_stats()

            if stats:
                col_stat1, col_stat2 = st.columns(2)

                with col_stat1:
                    st.markdown(f"""
                    <div class="stat-card-pro">
                        <div class="stat-value-pro">{stats.get('total_commands', 0)}</div>
                        <div class="stat-label-pro">Interactions</div>
                    </div>
                    """, unsafe_allow_html=True)

                with col_stat2:
                    confidence = stats.get('average_confidence', 0)
                    st.markdown(f"""
                    <div class="stat-card-pro">
                        <div class="stat-value-pro">{confidence * 100:.0f}%</div>
                        <div class="stat-label-pro">Confiance</div>
                    </div>
                    """, unsafe_allow_html=True)

                # Graphique des types
                if stats.get('command_types'):
                    st.markdown("#### üìä **Distribution des Types**")
                    types_df = pd.DataFrame(
                        list(stats['command_types'].items()),
                        columns=['Type', 'Nombre']
                    )
                    st.bar_chart(types_df.set_index('Type'))

        with col_right2:
            # Gestion du syst√®me
            st.markdown("### ‚öôÔ∏è **Gestion Syst√®me**")

            if st.button("üîÑ **Red√©marrer Session**", use_container_width=True, type="secondary"):
                st.session_state.clear()
                st.rerun()

            if st.button("üìã **Journal Syst√®me**", use_container_width=True, type="secondary"):
                if os.path.exists('assistant.log'):
                    with open('assistant.log', 'r', encoding='utf-8') as f:
                        logs = f.read()[-8000:]  # Derniers 8000 caract√®res

                    with st.expander("**üîç Journal Syst√®me D√©taill√©**", expanded=True):
                        st.code(logs, language='log')
                else:
                    st.info("üìù **Aucun journal disponible**\n\nLe journal sera cr√©√© apr√®s la premi√®re interaction.")

            # Informations syst√®me
            st.markdown("---")
            st.markdown("### üîß **Informations Techniques**")

            engines = self.assistant.voice_manager.get_available_engines()
            engine_count = len(engines)

            st.metric("üé§ Moteurs TTS", engine_count)
            st.metric("üíæ Historique", len(self.assistant.conversation_history))

            # Statut API
            api_status = "‚úÖ Configur√©e" if self.assistant.weather_api_key else "‚ö†Ô∏è Requise"
            st.metric("üå§Ô∏è API M√©t√©o", api_status)

    def render_input_section(self):
        """Afficher la section de saisie professionnelle"""
        st.markdown("---")
        st.markdown("### ‚å®Ô∏è **Saisie Professionnelle**")

        col_input1, col_input2 = st.columns([4, 1])

        with col_input1:
            user_input = st.text_area(
                "**Tapez votre requ√™te professionnelle :**",
                placeholder="""Exemples de requ√™tes professionnelles :
‚Ä¢ "Analysez les tendances du march√© actuel"
‚Ä¢ "Calculez le ROI d'un investissement de 50 000‚Ç¨ √† 7% sur 10 ans"
‚Ä¢ "Fournissez un rapport m√©t√©o professionnel pour Paris"
‚Ä¢ "Recherchez les derni√®res innovations en intelligence artificielle"
‚Ä¢ "Donnez un conseil strat√©gique pour le d√©veloppement d'entreprise"
‚Ä¢ "Expliquez les principes du leadership transformationnel" """,
                height=120,
                key="text_input_pro"
            )

        with col_input2:
            st.markdown("<br>", unsafe_allow_html=True)
            if st.button("üì§ **Envoyer Professionnellement**",
                         type="primary",
                         use_container_width=True,
                         key="send_button_pro"):
                if user_input and user_input.strip():
                    with st.spinner("**Traitement professionnel en cours...**"):
                        response = self.assistant.process_command(user_input.strip())
                        st.session_state.last_response = response
                        st.rerun()
                else:
                    st.warning("‚ö†Ô∏è Veuillez saisir une requ√™te valide.")

    def render_footer(self):
        """Afficher le pied de page professionnel"""
        st.markdown("---")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("""
            **ü§ñ Assistant Vocal Professionnel Elite v4.0**

            *Syst√®me de communication IA avanc√©*
            *D√©velopp√© pour l'excellence professionnelle*
            *Garantie de r√©ponse √† 100% des questions*

            **Certification :** ISO 9001:2025 (simul√©)
            """)

        with col2:
            now = dt.now()
            st.markdown(f"""
            **üïê Heure syst√®me :** {now.strftime('%H:%M:%S')}
            **üìÖ Date :** {now.strftime('%A %d %B %Y')}

            **Fuseau horaire :** Europe/Paris
            **Version :** 4.0.1 Professionnelle

            **Statut :** ‚úÖ Op√©rationnel
            **Performance :** ‚ö° Optimale
            """)

        with col3:
            st.markdown("""
            **üìû Support Professionnel**

            [üìö Documentation](https://github.com) | 
            [üêõ Rapporter un Bug](https://github.com/issues) |
            [üí° Suggestions](https://github.com/discussions)

            **Confidentialit√© :** üîí Niveau Entreprise
            **SLA :** 99.9% Disponibilit√©

            ¬© 2024 Assistant Vocal Pro. Tous droits r√©serv√©s.
            """)

    def run(self):
        """Ex√©cuter l'application professionnelle"""
        try:
            self.render_header()
            self.render_sidebar()
            self.render_main_content()
            self.render_input_section()
            self.render_footer()

        except Exception as e:
            st.error(f"‚ùå **Erreur critique dans l'application :** {str(e)}")
            logger.error(f"Erreur application : {e}", exc_info=True)

            # Mode de secours professionnel
            with st.expander("üîß **Mode Diagnostic Professionnel**", expanded=True):
                st.warning("**L'application rencontre des difficult√©s techniques.**")

                st.markdown("**Solutions professionnelles :**")
                st.markdown("""
                1. **Red√©marrer l'application** - Rafra√Æchir la page (F5)
                2. **V√©rifier les d√©pendances** - Assurez-vous que tous les modules sont install√©s
                3. **Consulter les logs** - Voir les journaux syst√®me pour plus de d√©tails
                4. **Contacter le support** - En cas de persistance du probl√®me
                """)

                # Informations syst√®me
                st.markdown("**Informations syst√®me :**")
                st.write(f"**Python :** {sys.version}")
                st.write(f"**Streamlit :** {st.__version__}")
                st.write(f"**Syst√®me :** {sys.platform}")

                # Test des modules critiques
                st.markdown("**Test des modules critiques :**")
                critical_modules = ['streamlit', 'requests', 'pandas', 'numpy']

                for module in critical_modules:
                    try:
                        __import__(module)
                        st.success(f"‚úÖ {module}")
                    except ImportError:
                        st.error(f"‚ùå {module} - REQUIS")


# ========== POINT D'ENTR√âE PROFESSIONNEL ==========
def main():
    """Fonction principale professionnelle"""
    try:
        # Message de d√©marrage professionnel
        st.set_page_config(
            page_title="ü§ñ Assistant Vocal Professionnel Elite",
            page_icon="ü§ñ",
            layout="wide"
        )

        # V√©rification initiale
        st.markdown("""
        <style>
            /* Animation de chargement professionnelle */
            @keyframes professionalPulse {
                0%, 100% { opacity: 0.8; }
                50% { opacity: 1; }
            }

            .loading-container {
                text-align: center;
                padding: 100px 20px;
                animation: professionalPulse 2s infinite;
            }
        </style>
        """, unsafe_allow_html=True)

        # Cr√©er et ex√©cuter l'interface
        with st.spinner("**Initialisation de l'Assistant Professionnel Elite...**"):
            time.sleep(0.5)
            ui = ProfessionalAssistantUI()
            ui.run()

    except Exception as e:
        # Gestion d'erreur professionnelle
        st.error(f"""
        ## ‚ö†Ô∏è **Initialisation √©chou√©e**

        **Erreur :** {str(e)}

        **Actions recommand√©es :**
        1. V√©rifiez votre connexion Internet
        2. Assurez-vous que Python 3.8+ est install√©
        3. Installez les d√©pendances avec `pip install -r requirements.txt`
        4. Contactez le support technique
        """)

        logger.error(f"Erreur initialisation : {e}", exc_info=True)

        # Mode de secours minimal
        st.markdown("---")
        st.markdown("### üîß **Mode de Secours Minimal**")

        simple_query = st.text_input("Posez votre question (mode texte uniquement) :")

        if simple_query and st.button("Envoyer"):
            st.info(f"**Mode secours activ√© pour :** {simple_query}")
            st.warning("""
            **Fonctionnalit√©s limit√©es en mode secours :**
            - Pas de reconnaissance vocale
            - Pas de synth√®se vocale
            - R√©ponses basiques
            - Pas d'historique
            """)

            # R√©ponse basique
            st.success(f"""
            **R√©ponse de secours :**

            Merci pour votre question concernant "{simple_query}". 

            En mode de secours, je ne peux fournir qu'une r√©ponse basique. 
            Veuillez r√©installer l'application compl√®te pour une assistance professionnelle.

            **Question re√ßue :** {simple_query}
            **Heure :** {dt.now().strftime('%H:%M')}
            """)


# ========== EX√âCUTION ==========
if __name__ == "__main__":
    main()